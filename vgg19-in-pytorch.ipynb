{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageNet\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport os\nfrom torchvision.datasets import CIFAR10\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:57:03.510020Z","iopub.execute_input":"2025-07-19T12:57:03.510715Z","iopub.status.idle":"2025-07-19T12:57:15.395090Z","shell.execute_reply.started":"2025-07-19T12:57:03.510690Z","shell.execute_reply":"2025-07-19T12:57:15.394305Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# CIFAR-10 has 10 classes and image size 32x32. We resize to 224x224 to match VGG input.\ntransform_train = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ntrain_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:57:15.396408Z","iopub.execute_input":"2025-07-19T12:57:15.396878Z","iopub.status.idle":"2025-07-19T12:57:20.370860Z","shell.execute_reply.started":"2025-07-19T12:57:15.396852Z","shell.execute_reply":"2025-07-19T12:57:20.370105Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:01<00:00, 105MB/s]  \n/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class VGG19(nn.Module):\n    def __init__(self, num_classes=10):\n        super(VGG19, self).__init__()\n\n        # Feature extraction layers: Convolutional and pooling layers\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(\n                3, 64, kernel_size=3, padding=1\n            ),  # 3 input channels, 64 output channels, 3x3 kernel, 1 padding\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(\n                kernel_size=2, stride=2\n            ),  # Max pooling with 2x2 kernel and stride 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        # Pooling Layer\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n\n        # Fully connected layers for classification\n        self.classifier = nn.Sequential(\n            nn.Linear(\n                512 * 7 * 7, 4096\n            ),  # 512 channels, 7x7 spatial dimensions after max pooling\n            nn.ReLU(),\n            nn.Dropout(0.5),  # Dropout layer with 0.5 dropout probability\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, num_classes),  # Output layer with 'num_classes' output units\n        )\n\n    def forward(self, x):\n        x = self.feature_extractor(x)  # Pass input through the feature extractor layers\n        x = self.avgpool(x)  # Pass Data through a pooling layer\n        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layers\n        x = self.classifier(x)  # Pass flattened output through the classifier layers\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:57:20.371528Z","iopub.execute_input":"2025-07-19T12:57:20.371728Z","iopub.status.idle":"2025-07-19T12:57:20.381364Z","shell.execute_reply.started":"2025-07-19T12:57:20.371712Z","shell.execute_reply":"2025-07-19T12:57:20.380650Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #if using mac put 'mps' instead of 'cuda'\n\nmodel = VGG19()  # Your custom VGG19 class\n\n# Wrap with DataParallel\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:57:20.382781Z","iopub.execute_input":"2025-07-19T12:57:20.383131Z","iopub.status.idle":"2025-07-19T12:57:22.038586Z","shell.execute_reply.started":"2025-07-19T12:57:20.383114Z","shell.execute_reply":"2025-07-19T12:57:22.037800Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from torchvision import models\nfrom torchsummary import summary\n\nsummary(model, input_size=(3, 224, 224))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T13:01:30.189614Z","iopub.execute_input":"2025-07-19T13:01:30.190217Z","iopub.status.idle":"2025-07-19T13:01:32.637102Z","shell.execute_reply.started":"2025-07-19T13:01:30.190194Z","shell.execute_reply":"2025-07-19T13:01:32.636370Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n            Conv2d-2         [-1, 64, 224, 224]           1,792\n              ReLU-3         [-1, 64, 224, 224]               0\n              ReLU-4         [-1, 64, 224, 224]               0\n            Conv2d-5         [-1, 64, 224, 224]          36,928\n              ReLU-6         [-1, 64, 224, 224]               0\n            Conv2d-7         [-1, 64, 224, 224]          36,928\n              ReLU-8         [-1, 64, 224, 224]               0\n         MaxPool2d-9         [-1, 64, 112, 112]               0\n        MaxPool2d-10         [-1, 64, 112, 112]               0\n           Conv2d-11        [-1, 128, 112, 112]          73,856\n             ReLU-12        [-1, 128, 112, 112]               0\n           Conv2d-13        [-1, 128, 112, 112]          73,856\n             ReLU-14        [-1, 128, 112, 112]               0\n           Conv2d-15        [-1, 128, 112, 112]         147,584\n             ReLU-16        [-1, 128, 112, 112]               0\n        MaxPool2d-17          [-1, 128, 56, 56]               0\n           Conv2d-18        [-1, 128, 112, 112]         147,584\n             ReLU-19        [-1, 128, 112, 112]               0\n        MaxPool2d-20          [-1, 128, 56, 56]               0\n           Conv2d-21          [-1, 256, 56, 56]         295,168\n             ReLU-22          [-1, 256, 56, 56]               0\n           Conv2d-23          [-1, 256, 56, 56]         295,168\n             ReLU-24          [-1, 256, 56, 56]               0\n           Conv2d-25          [-1, 256, 56, 56]         590,080\n             ReLU-26          [-1, 256, 56, 56]               0\n           Conv2d-27          [-1, 256, 56, 56]         590,080\n             ReLU-28          [-1, 256, 56, 56]               0\n           Conv2d-29          [-1, 256, 56, 56]         590,080\n             ReLU-30          [-1, 256, 56, 56]               0\n        MaxPool2d-31          [-1, 256, 28, 28]               0\n           Conv2d-32          [-1, 256, 56, 56]         590,080\n             ReLU-33          [-1, 256, 56, 56]               0\n           Conv2d-34          [-1, 256, 56, 56]         590,080\n             ReLU-35          [-1, 256, 56, 56]               0\n           Conv2d-36          [-1, 256, 56, 56]         590,080\n             ReLU-37          [-1, 256, 56, 56]               0\n        MaxPool2d-38          [-1, 256, 28, 28]               0\n           Conv2d-39          [-1, 512, 28, 28]       1,180,160\n             ReLU-40          [-1, 512, 28, 28]               0\n           Conv2d-41          [-1, 512, 28, 28]       1,180,160\n             ReLU-42          [-1, 512, 28, 28]               0\n           Conv2d-43          [-1, 512, 28, 28]       2,359,808\n             ReLU-44          [-1, 512, 28, 28]               0\n           Conv2d-45          [-1, 512, 28, 28]       2,359,808\n             ReLU-46          [-1, 512, 28, 28]               0\n           Conv2d-47          [-1, 512, 28, 28]       2,359,808\n           Conv2d-48          [-1, 512, 28, 28]       2,359,808\n             ReLU-49          [-1, 512, 28, 28]               0\n           Conv2d-50          [-1, 512, 28, 28]       2,359,808\n             ReLU-51          [-1, 512, 28, 28]               0\n             ReLU-52          [-1, 512, 28, 28]               0\n           Conv2d-53          [-1, 512, 28, 28]       2,359,808\n        MaxPool2d-54          [-1, 512, 14, 14]               0\n             ReLU-55          [-1, 512, 28, 28]               0\n        MaxPool2d-56          [-1, 512, 14, 14]               0\n           Conv2d-57          [-1, 512, 14, 14]       2,359,808\n             ReLU-58          [-1, 512, 14, 14]               0\n           Conv2d-59          [-1, 512, 14, 14]       2,359,808\n           Conv2d-60          [-1, 512, 14, 14]       2,359,808\n             ReLU-61          [-1, 512, 14, 14]               0\n           Conv2d-62          [-1, 512, 14, 14]       2,359,808\n             ReLU-63          [-1, 512, 14, 14]               0\n             ReLU-64          [-1, 512, 14, 14]               0\n           Conv2d-65          [-1, 512, 14, 14]       2,359,808\n           Conv2d-66          [-1, 512, 14, 14]       2,359,808\n             ReLU-67          [-1, 512, 14, 14]               0\n           Conv2d-68          [-1, 512, 14, 14]       2,359,808\n             ReLU-69          [-1, 512, 14, 14]               0\n        MaxPool2d-70            [-1, 512, 7, 7]               0\n             ReLU-71          [-1, 512, 14, 14]               0\n           Conv2d-72          [-1, 512, 14, 14]       2,359,808\n             ReLU-73          [-1, 512, 14, 14]               0\n        MaxPool2d-74            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-75            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-76            [-1, 512, 7, 7]               0\n           Linear-77                 [-1, 4096]     102,764,544\n             ReLU-78                 [-1, 4096]               0\n           Linear-79                 [-1, 4096]     102,764,544\n             ReLU-80                 [-1, 4096]               0\n          Dropout-81                 [-1, 4096]               0\n          Dropout-82                 [-1, 4096]               0\n           Linear-83                 [-1, 4096]      16,781,312\n           Linear-84                 [-1, 4096]      16,781,312\n             ReLU-85                 [-1, 4096]               0\n             ReLU-86                 [-1, 4096]               0\n          Dropout-87                 [-1, 4096]               0\n          Dropout-88                 [-1, 4096]               0\n           Linear-89                   [-1, 10]          40,970\n           Linear-90                   [-1, 10]          40,970\n            VGG19-91                   [-1, 10]               0\n            VGG19-92                   [-1, 10]               0\n================================================================\nTotal params: 279,222,420\nTrainable params: 279,222,420\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 477.36\nParams size (MB): 1065.15\nEstimated Total Size (MB): 1543.08\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def train(model, loader, optimizer, criterion):\n    model.train()\n    running_loss = 0\n    correct = 0\n    total = 0\n    for inputs, targets in tqdm(loader):\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    return running_loss / len(loader), correct / total\n\ndef validate(model, loader, criterion):\n    model.eval()\n    running_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n    return running_loss / len(loader), correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T08:50:19.304896Z","iopub.execute_input":"2025-07-19T08:50:19.305569Z","iopub.status.idle":"2025-07-19T08:50:19.311830Z","shell.execute_reply.started":"2025-07-19T08:50:19.305546Z","shell.execute_reply":"2025-07-19T08:50:19.311092Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"best_acc = 0.0\nos.makedirs(\"checkpoints\", exist_ok=True)\n\nfor epoch in range(1, 91):  # 90 epochs like VGG paper\n    print(f\"\\nEpoch {epoch}\")\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = validate(model, test_loader, criterion)\n    scheduler.step()\n\n    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n    print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n\n    # Save last weights\n    torch.save(model.state_dict(), \"checkpoints/vgg19_last.pth\")\n\n    # Save best weights\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), \"checkpoints/vgg19_best.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}